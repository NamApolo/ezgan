{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an illustration of a very simple generative adversarial network, built with TensorFlow. It generates images that look like handwritten digits from the MNIST dataset.\n",
    "\n",
    "For the greatest possible clarity, I've adapted two well-documented networks as the discriminator and the generator. [The convolutional neural network from TensorFlow's documentation](https://www.tensorflow.org/tutorials/mnist/pros/) serves as the discriminator, and [Tim O'Shea's Keras model](http://www.kdnuggets.com/2016/07/mnist-generative-adversarial-model-keras.html) as the generator.\n",
    "\n",
    "Other crucial insights come from papers by [Ian Goodfellow](https://arxiv.org/abs/1701.00160) and [Alec Radford](https://arxiv.org/abs/1511.06434), and [Soumith Chintala](https://github.com/soumith/ganhacks).\n",
    "\n",
    "**This is a work in progress**, and is full of all manner of hacks and hard-coded shortcuts that will disappear or (hopefully) become more elegant as I make revisions.\n",
    "\n",
    "The code here is written for TensorFlow v0.12, but can be made to run on earlier versions with some quick changesâ€”in particular, replacing `tf.global_variable_initializer()` with `tf.initialize_all_variables()`. This script sends very helpful output to TensorBoard; to make it work with TensorBoard v0.11 and earlier, replace `tf.summary.scalar()` and `tf.summary.image()` with `tf.scalar_summary()` and `tf.image_summary()`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow.contrib.learn.python.learn.datasets.mnist as mn\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=False)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix disused scope stuff here\n",
    "\n",
    "def weight_variable(shape, name, sc='discriminator'):\n",
    "    return tf.get_variable(name, shape, initializer=tf.truncated_normal_initializer(0, 0.1))\n",
    "\n",
    "def bias_variable(shape, name, sc='discriminator'):\n",
    "    return tf.get_variable(name, shape, initializer=tf.constant_initializer(0.1))\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x, name):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('meta_variables') as scope:\n",
    "    # Hack to show in TensorBoard whether discriminator or generator is being trained\n",
    "    g_train_count = tf.placeholder(tf.int8)\n",
    "    tf.summary.scalar('Generator_training_cycles', g_train_count)\n",
    "    d_generated_train_count = tf.placeholder(tf.int8)\n",
    "    tf.summary.scalar('Discriminator_generated_training_cycles', d_generated_train_count)\n",
    "    d_mnist_train_count = tf.placeholder(tf.int8)\n",
    "    tf.summary.scalar('Discriminator_mnist_training_cycles', d_mnist_train_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the generator network; it includes a version of the discriminator so that gradients over the discriminator with respect to the generator weights are available to the generator's optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('generator') as scope:\n",
    "    z = tf.placeholder(tf.float32, shape=[None, 100], name=\"z\")\n",
    "\n",
    "    w1 = tf.Variable(tf.random_uniform([100, 3136], 0, 1), name='w1')\n",
    "    b1 = tf.Variable(tf.zeros([3136]), name='b1')\n",
    "    g1 = tf.matmul(z, w1) + b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5)\n",
    "    g1 = tf.nn.relu(g1)\n",
    "\n",
    "    # Generate 50 features\n",
    "    w2 = tf.Variable(tf.random_uniform([3, 3, 1, 50]))\n",
    "    b2 = tf.Variable(tf.random_uniform([50]))\n",
    "    g2 = tf.nn.conv2d(g1, w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5)\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "    # Generate 25 features\n",
    "    w3 = tf.Variable(tf.random_uniform([3, 3, 50, 25]))\n",
    "    b3 = tf.Variable(tf.random_uniform([25]))\n",
    "    g3 = tf.nn.conv2d(g2, w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5)\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "    # Final convolution with one output channel\n",
    "    w4 = tf.Variable(tf.random_uniform([1, 1, 25, 1]))\n",
    "    b4 = tf.Variable(tf.random_uniform([1]))\n",
    "    g4 = tf.nn.conv2d(g3, w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = tf.sigmoid(g4)\n",
    "\n",
    "    #Using tf.squeeze to eliminate final dimension that would usually be used for color channels\n",
    "    generator_images = tf.reshape(tf.squeeze(g4), [50, 784])\n",
    "    \n",
    "    generator_trainable_variables = [w1, b1, w2, b2, w3, b3, w4, b4]\n",
    "\n",
    "    # Per Goodfellow, the last layer of the generator is not normalized.\n",
    "    \n",
    "    x = generator_images\n",
    "    images_for_tensorboard = tf.reshape(generator_images, [-1, 28, 28, 1])\n",
    "    tf.summary.image('Generated_images', images_for_tensorboard, max_outputs=50)\n",
    "    \n",
    "    # Let's combine the MNIST images and labels via placeholder with the generated images\n",
    "    \n",
    "    W = tf.Variable(tf.zeros([784, 1]), name=\"W\")\n",
    "    b = tf.Variable(tf.zeros([1]), name=\"b\")\n",
    "\n",
    "    W_conv1 = weight_variable([5, 5, 1, 32], 'W_conv1')\n",
    "    b_conv1 = bias_variable([32], 'b_conv1')\n",
    "\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1, name='h_conv1')\n",
    "    h_pool1 = max_pool_2x2(h_conv1, name='h_pool1')\n",
    "\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64], 'W_conv2')\n",
    "    b_conv2 = bias_variable([64], name='b_conv2')\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2, name='h_conv2')\n",
    "    h_pool2 = max_pool_2x2(h_conv2, name='h_pool2')\n",
    "\n",
    "    W_fc1 = weight_variable([7 * 7 * 64, 1024], name='W_fc1')\n",
    "    b_fc1 = bias_variable([1024], name='b_fc1')\n",
    "\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64], name='h_pool2_flat')\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1, name='h_fc1')\n",
    "\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, name='h_fc1_drop')\n",
    "\n",
    "    W_fc2 = weight_variable([1024, 1], name='W_fc2')\n",
    "    b_fc2 = bias_variable([1], name='b_fc2')\n",
    "\n",
    "    y_conv = tf.sigmoid(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the discriminator network. Note that we don't reinitialize the weights and biases; we use the same weights and biases that we initialized for the generator network, but describe new layers for them that take an input from a placeholder, `d_x`, instead of taking input straight from the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('discriminator') as scope:\n",
    "    d_x = tf.placeholder(tf.float32, shape=[None, 784], name='d_x')\n",
    "    # d_y_ = tf.placeholder(tf.float32, shape=[None, 2], name='d_y_')\n",
    "\n",
    "    d_x_image = tf.reshape(d_x, [-1,28,28,1], name='d_x_image')\n",
    "\n",
    "    d_h_conv1 = tf.nn.relu(conv2d(d_x_image, W_conv1) + b_conv1, name='d_h_conv1')\n",
    "    d_h_pool1 = max_pool_2x2(d_h_conv1, name='d_h_pool1')\n",
    "\n",
    "    d_h_conv2 = tf.nn.relu(conv2d(d_h_pool1, W_conv2) + b_conv2, name='d_h_conv2')\n",
    "    d_h_pool2 = max_pool_2x2(d_h_conv2, name='d_h_pool2')\n",
    "\n",
    "    d_h_pool2_flat = tf.reshape(d_h_pool2, [-1, 7*7*64], name='d_h_pool2_flat')\n",
    "    d_h_fc1 = tf.nn.relu(tf.matmul(d_h_pool2_flat, W_fc1) + b_fc1, name='d_h_fc1')\n",
    "\n",
    "    d_h_fc1_drop = tf.nn.dropout(d_h_fc1, keep_prob, name='d_h_fc1_drop')\n",
    "\n",
    "    d_y_conv = tf.sigmoid(tf.matmul(d_h_fc1_drop, W_fc2) + b_fc2)\n",
    "    \n",
    "    # There's probably a clever way to refer to the losses of G and D\n",
    "    # rather than these accuracy stats.\n",
    "    generated_accuracy = 1 - tf.reduce_mean(d_y_conv[0:50])\n",
    "    tf.summary.scalar('generated_accuracy', generated_accuracy)\n",
    "    mnist_accuracy = tf.reduce_mean(d_y_conv[50:100])\n",
    "    tf.summary.scalar('mnist_accuracy', mnist_accuracy)\n",
    "    \n",
    "    discriminator_trainable_variables = [W_conv1, b_conv1, W_conv2, b_conv2,\n",
    "                                     W_fc1, b_fc1, W_fc2, b_fc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, shape=[None, 1], name='y_')\n",
    "\n",
    "discriminator_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(d_y_conv, y_))\n",
    "\n",
    "tf.summary.scalar('discriminator_loss', discriminator_loss)\n",
    "\n",
    "generator_loss = -1 * tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(y_conv, y_))\n",
    "tf.summary.scalar('generator_loss', generator_loss)\n",
    "\n",
    "discriminator_optimize = tf.train.AdamOptimizer(1e-5, name='discriminator_train') \\\n",
    "    .minimize(discriminator_loss, var_list=discriminator_trainable_variables)\n",
    "generator_optimize = tf.train.AdamOptimizer(1e-3, name='generator_train') \\\n",
    "    .minimize(generator_loss, var_list=generator_trainable_variables)\n",
    "\n",
    "generator_weights_mean = tf.reduce_mean(tf.abs(w1)) + tf.reduce_mean(tf.abs(w2)) + tf.reduce_mean(tf.abs(w3)) + tf.reduce_mean(tf.abs(w4))\n",
    "tf.summary.scalar('generator_weights_mean', generator_weights_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to eventually reach a point where the discriminator correctly classifies all real MNIST images as MNIST images, and classifies generated images as MNIST images about 50% of the time. There are several failure modes that we need to avoid:\n",
    "* **Discriminator accuracy goes to 100%**: this leaves practically no gradients for the generator's optimizer.\n",
    "* **Discriminator accuracy goes to 0%**\n",
    "* **Divergent discriminator accuracy**: the discriminator classifies generated images at about 50%, but drops toward 0% accuracy on real MNIST images.\n",
    "\n",
    "To stay balanced between these, we have separate functions to train the generator, train the discriminator on real MNIST images, and train the discriminator on generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_discriminator_generated(combined_labels, generated_labels):\n",
    "    # Grab some generated images\n",
    "    random = np.random.normal(size=(50, 100))\n",
    "    mnist_batch = mnist.train.next_batch(50)[0]\n",
    "    g_images = sess.run(generator_images, {z: random})\n",
    "    \n",
    "    _ = sess.run(discriminator_optimize, {d_x: g_images, keep_prob: 0.5, y_: generated_labels})\n",
    "    \n",
    "    random = np.random.normal(size=(50, 100))\n",
    "    g_images = sess.run(generator_images, {z: random})\n",
    "    mnist_batch = mnist.validation.next_batch(50)[0]\n",
    "    combined_images = np.concatenate((g_images, mnist_batch))\n",
    "    \n",
    "    ga, ma = sess.run([generated_accuracy, mnist_accuracy], {d_x: combined_images, keep_prob: 1})\n",
    "    return ga, ma\n",
    "\n",
    "def train_discriminator_mnist(combined_labels, mnist_labels):\n",
    "    mnist_batch = mnist.train.next_batch(50)[0]\n",
    "    \n",
    "    _ = sess.run(discriminator_optimize, {d_x: mnist_batch, keep_prob: 0.5, y_: mnist_labels})\n",
    "    \n",
    "    random = np.random.normal(size=(50, 100))\n",
    "    g_images = sess.run(generator_images, {z: random})\n",
    "    mnist_batch = mnist.validation.next_batch(50)[0]\n",
    "    combined_images = np.concatenate((g_images, mnist_batch))\n",
    "    \n",
    "    ga, ma = sess.run([generated_accuracy, mnist_accuracy], {d_x: combined_images, keep_prob: 1})\n",
    "    return ga, ma\n",
    "\n",
    "def train_discriminator_combined(combined_labels):\n",
    "    random = np.random.normal(size=(50, 100))\n",
    "    mnist_batch = mnist.train.next_batch(50)[0]\n",
    "    g_images = sess.run(generator_images, {z: random})\n",
    "    combined_images = np.concatenate((g_images, mnist_batch))\n",
    "    \n",
    "    _ = sess.run(discriminator_optimize, {d_x: combined_images, keep_prob: 0.5, y_: combined_labels})\n",
    "    \n",
    "    random = np.random.normal(size=(50, 100))\n",
    "    mnist_batch = mnist.train.next_batch(50)[0]\n",
    "    g_images = sess.run(generator_images, {z: random})\n",
    "    combined_images = np.concatenate((g_images, mnist_batch))\n",
    "    \n",
    "    ga, ma = sess.run([generated_accuracy, mnist_accuracy], {d_x: combined_images, keep_prob: 1})\n",
    "    return ga, ma\n",
    "\n",
    "def train_generator(generated_labels):\n",
    "    random = np.random.normal(size=(50, 100))\n",
    "    g_images, gl, _ = sess.run([generator_images, generator_loss, generator_optimize], {z: random, y_: generated_labels, keep_prob: 1})\n",
    "    \n",
    "    mnist_batch = mnist.validation.next_batch(50)[0]\n",
    "    combined_images = np.concatenate((g_images, mnist_batch))\n",
    "    ga, ma = sess.run([generated_accuracy, mnist_accuracy], {d_x: combined_images, keep_prob: 1})\n",
    "    return g_images, ga, ma\n",
    "\n",
    "def get_combined_images():\n",
    "    random = np.random.normal(size=(50, 100))\n",
    "    g_images = sess.run(generator_images, {z: random})\n",
    "    validation_images = mnist.validation.next_batch(50)[0]\n",
    "    return np.concatenate((g_images, validation_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the discriminator's accuracy over generated images is less than 50%, we train the discriminator over generated images. If the discriminator's accuracy over real MNIST images is less than 80%, we train it over MNIST images. Otherwise, we train the generator.\n",
    "\n",
    "In my experience, the generator winds up being trained almost exclusively for the first several thousand iterations, then settles into a balance where the iterations are given over about 45% to generator training, 35% to discriminator training over MNIST images, and 20% discriminator training over generated images. The greatest progress in developing recognizable images is made once the system reaches this balance.\n",
    "\n",
    "Summary statistics illustrating the ratio of discriminator and generator training cycles are sent to TensorBoard. Recognizable digits begin to emerge after about 20,000 iterations, and improve markedly for the 50,000 or so iterations after that. Every thousand iterations takes about 10 minutes on my laptop, or one minute on an [AWS P2 GPU-enabled machine](https://aws.amazon.com/ec2/instance-types/p2/), so a full 100,000 iterations should take 16 hours on a laptop or an hour and a half on a P2 instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# It's useful to track changes in the generator's weights\n",
    "# to see how quickly it's being optimized.\n",
    "last_weights = sess.run([w1, w2, w3, w4])\n",
    "\n",
    "generated_labels = np.array([[0.] for i in range(50)])\n",
    "# We try to get the discriminator to classify MNIST images as 0.9 rather than 1.0;\n",
    "# this is label smoothing, described by Goodfellow.\n",
    "mnist_labels = np.array([[0.9] for i in range(50)])\n",
    "combined_labels = np.concatenate((generated_labels, mnist_labels))\n",
    "\n",
    "# Start by running the generator\n",
    "g_images, ga, ma = train_generator(generated_labels)\n",
    "\n",
    "# ga = discriminator accuracy over generated images\n",
    "# ma = discriminator accuracy over real MNIST images\n",
    "\n",
    "d_generated_train_counter = 0\n",
    "d_mnist_train_counter = 0\n",
    "g_train_counter = 0\n",
    "\n",
    "for i in range(100000):\n",
    "    if ga < 0.5:\n",
    "        # Train discriminator over generated images\n",
    "        ga, ma = train_discriminator_generated(combined_labels, generated_labels)\n",
    "        d_generated_train_counter += 1\n",
    "    elif ma < 0.8:\n",
    "        # Train discriminator over real MNIST images\n",
    "        ga, ma = train_discriminator_mnist(combined_labels, mnist_labels)\n",
    "        d_mnist_train_counter += 1\n",
    "    else:\n",
    "        # Train generator\n",
    "        g_images, ga, ma = train_generator(generated_labels)\n",
    "        g_train_counter += 1\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        # Every 10 iterations, send summary statistics to TensorBoard\n",
    "        random = np.random.normal(size=(50, 100))\n",
    "        g_images = sess.run(generator_images, {z: random})\n",
    "        summary = sess.run(merged, {d_x: g_images, keep_prob: 1, z: np.random.normal(size=(50, 100)),\n",
    "                                    y_: generated_labels, g_train_count: g_train_counter,\n",
    "                                    d_generated_train_count: d_generated_train_counter,\n",
    "                                    d_mnist_train_count: d_mnist_train_counter})\n",
    "        writer.add_summary(summary, i)\n",
    "        d_mnist_train_counter, d_generated_train_counter, g_train_counter = 0, 0, 0\n",
    "    if i % 100 == 0:\n",
    "        combined_images = get_combined_images()\n",
    "\n",
    "        current_weights = sess.run([w1, w2, w3, w4])\n",
    "        ga, ma = sess.run([generated_accuracy, mnist_accuracy], {d_x: combined_images, keep_prob: 1})\n",
    "        print(i, \"MNIST acc:\", ma, \"Gen acc:\", ga, \"at\", datetime.datetime.now())\n",
    "        \n",
    "        # Summarize change in the generator's weights. If this tends toward zero\n",
    "        # within the first 100,000 iterations, there's something wrong.\n",
    "        weight_diff_sum = 0\n",
    "        for i in range(4):\n",
    "            weight_diff_sum += np.mean(np.absolute(np.absolute(last_weights[i]) - np.absolute(current_weights[i])))\n",
    "        print(\"Weight differences:\", weight_diff_sum)\n",
    "        last_weights = current_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see some of the images produced by the generator. (The generator has also been sending its images to TensorBoard regularly; click the \"images\" tab in TensorBoard to see them as this runs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random = np.random.normal(size=(50, 100))\n",
    "g_images = sess.run(generator_images, {z: random}).squeeze().reshape([50, 784])\n",
    "d_classifications = sess.run(d_y_conv, {d_x: g_images, keep_prob: 1})\n",
    "\n",
    "for i in range(50):\n",
    "    # Print the discriminator's classification of this image\n",
    "    print(d_classifications[i])\n",
    "    plt.imshow(g_images[i].reshape([28, 28]), cmap='Greys', interpolation='none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as a sanity check, let's look at some real MNIST images and make sure that the discriminator correctly classifies them as real MINST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_classifications = sess.run(d_y_conv, {d_x: validation_batch, keep_prob: 1})\n",
    "print(d_classifications)\n",
    "for i in range(50):\n",
    "    img = validation_batch[i]\n",
    "    print(d_classifications[i])\n",
    "    plt.imshow(img.reshape([28, 28]), cmap='Greys')\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow3]",
   "language": "python",
   "name": "Python [tensorflow3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
