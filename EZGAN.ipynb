{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an illustration of a very simple generative adversarial network, built with TensorFlow. It generates images that look like handwritten digits from the MNIST dataset.\n",
    "\n",
    "For the greatest possible clarity, I've adapted two well-documented networks as the discriminator and the generator. [The convolutional neural network from TensorFlow's documentation](https://www.tensorflow.org/tutorials/mnist/pros/) serves as the discriminator, and [Tim O'Shea's Keras model](http://www.kdnuggets.com/2016/07/mnist-generative-adversarial-model-keras.html) as the generator.\n",
    "\n",
    "[Adit Deshpande](https://adeshpande3.github.io/) suggested a clever way to call the generator and discriminator as functions; his method is implemented below. Other crucial insights come from papers by [Ian Goodfellow](https://arxiv.org/abs/1701.00160) and [Alec Radford](https://arxiv.org/abs/1511.06434), and [Soumith Chintala](https://github.com/soumith/ganhacks).\n",
    "\n",
    "**This is a work in progress**, and is full of all manner of hacks and hard-coded shortcuts that will disappear or (hopefully) become more elegant as I make revisions.\n",
    "\n",
    "The code here is written for TensorFlow v0.12, but can be made to run on earlier versions with some quick changes—in particular, replacing `tf.global_variable_initializer()` with `tf.initialize_all_variables()`. This script sends very helpful output to TensorBoard; to make it work with TensorBoard v0.11 and earlier, replace `tf.summary.scalar()` and `tf.summary.image()` with `tf.scalar_summary()` and `tf.image_summary()`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a clever structure suggested by [Adit Deshpande](https://adeshpande3.github.io/), the discriminator and generator networks will sit inside separate functions that we can call as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the discriminator network. It takes `x_image` and returns a real/fake classification. As you'll see below, we can either feed `x_image` through a placeholder, or from another tensor—for instance, the output of the generator.\n",
    "\n",
    "This network structure is taken directly from TensorFlow's [Deep MNIST for Experts](https://www.tensorflow.org/tutorials/mnist/pros/) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x_image, reuse=False):\n",
    "    if (reuse):\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "    # First convolutional and pool layers\n",
    "    # These search for 32 different 5 x 5 pixel features\n",
    "    d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "    d1 = tf.nn.conv2d(input=x_image, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d1 = d1 + d_b1\n",
    "    d1 = tf.nn.relu(d1)\n",
    "    d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Second convolutional and pool layers\n",
    "    # These search for 64 different 5 x 5 pixel features\n",
    "    d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "    d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d2 = d2 + d_b2\n",
    "    d2 = tf.nn.relu(d2)\n",
    "    d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # First fully connected layer\n",
    "    d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "    d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "    d3 = tf.matmul(d3, d_w3)\n",
    "    d3 = d3 + d_b3\n",
    "    d3 = tf.nn.relu(d3)\n",
    "\n",
    "    # Second fully connected layer\n",
    "    d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "\n",
    "    # Final layer\n",
    "    d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "    # d4 dimensions: batch_size x 1\n",
    "\n",
    "    return d4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the generator. When it's called, it starts by creating a batch of random noise from the latente space $z$, then passes it through a handful of convolutions to produce a 28 x 28 image.\n",
    "\n",
    "This structure is borrowed [from Tim O'Shea](http://www.kdnuggets.com/2016/07/mnist-generative-adversarial-model-keras.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(batch_size, z_dim):\n",
    "    z = tf.random_normal([batch_size, z_dim], mean=0, stddev=1, name='z')\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "\n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "\n",
    "    # No batch normalization at the final layer, but we do add\n",
    "    # a sigmoid activator to make the generated images crisper.\n",
    "    # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set up our losses and optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "batch_size = 50\n",
    "z_dimensions = 100\n",
    "\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [None,28,28,1], name='x_placeholder')\n",
    "# x_placeholder is for feeding input images to the discriminator\n",
    "\n",
    "Gz = generator(batch_size, z_dimensions)\n",
    "# Gz holds the generated images\n",
    "\n",
    "Dx = discriminator(x_placeholder)\n",
    "# Dx hold the discriminator's prediction probabilities\n",
    "# for real MNIST images\n",
    "\n",
    "Dg = discriminator(Gz, reuse=True)\n",
    "# Dg holds discriminator prediction probabilities for generated images\n",
    "\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(Dg, tf.ones_like(Dg)))\n",
    "\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(Dx, tf.fill([batch_size, 1], 0.9)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(Dg, tf.zeros_like(Dg)))\n",
    "d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "# Train the discriminator\n",
    "d_trainer_fake = tf.train.AdamOptimizer(0.001).minimize(d_loss_fake, var_list=d_vars)\n",
    "d_trainer_real = tf.train.AdamOptimizer(0.001).minimize(d_loss_real, var_list=d_vars)\n",
    "\n",
    "# Train the generator\n",
    "g_trainer = tf.train.AdamOptimizer(0.004).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's where we pass helpful summary scalars and sample images to TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "\n",
    "d_real_count_ph = tf.placeholder(tf.float32)\n",
    "d_fake_count_ph = tf.placeholder(tf.float32)\n",
    "g_count_ph = tf.placeholder(tf.float32)\n",
    "\n",
    "tf.summary.scalar('d_real_count', d_real_count_ph)\n",
    "tf.summary.scalar('d_fake_count', d_fake_count_ph)\n",
    "tf.summary.scalar('g_count', g_count_ph)\n",
    "\n",
    "# Sanity check to see how the discriminator evaluates\n",
    "# generated and real MNIST images\n",
    "d_on_generated = tf.reduce_mean(discriminator(generator(batch_size, z_dimensions)))\n",
    "d_on_real = tf.reduce_mean(discriminator(x_placeholder))\n",
    "\n",
    "tf.summary.scalar('d_on_generated_eval', d_on_generated)\n",
    "tf.summary.scalar('d_on_real_eval', d_on_real)\n",
    "\n",
    "images_for_tensorboard = generator(batch_size, z_dimensions)\n",
    "tf.summary.image('Generated_images', images_for_tensorboard, 10)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to eventually reach a point where the discriminator correctly classifies nearly all real MNIST images as MNIST images, and classifies generated images as MNIST images about 50% of the time. There are several failure modes that we need to avoid:\n",
    "* **Discriminator losses approach zero**: this leaves practically no gradients for the generator's optimizer.\n",
    "* **Discriminator losses rise unbounded on generated images**: similarly, this leaves practically no gradient for the discriminator to improve, and the generator's training stalls, too, since the gradients it's reading suggest that it has achieved perfect performance.\n",
    "* **Divergent discriminator accuracy**: the discriminator learns a shortcut by either classifying everything as real or everything as generated. You can detect this by checking the discriminator's losses on generated images against the discriminator's losses on real images.\n",
    "\n",
    "To stay balanced between these, we use a controller in the training loop that runs each of the three training operations depending on their losses. Qualitatively speaking, the most rapid improvements in output come when the generator and discriminator are evenly matched; the controller avoids running a training operation when its network shows signs of overpowering the others.\n",
    "\n",
    "Here's our training loop. You'll need a writable directory in your current working directory called `tensorboard` for TensorBoard logs, and another one called `models` to store the five most recent checkpoints.\n",
    "\n",
    "Recognizable results should begin to appear before 10,000 cycles, and will improve after that. On a fast GPU machine, you can make it to 10,000 cycles in less than 10 minutes. It could take around 10 times as long to run on a desktop CPU. There are lots of random numbers involved, so you'll get different results every time you run this. In particular, it's likely to stall for upwards of 2,000 cycles at a time early on, but it should recover on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "gLoss = 1\n",
    "dLossFake, dLossReal = 0, 0\n",
    "d_real_count, d_fake_count, g_count = 0, 0, 0\n",
    "for i in range(50000):\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    if dLossFake > 0.7:\n",
    "        # Train discriminator on generated images\n",
    "        _, dLossReal, dLossFake, gLoss = sess.run([d_trainer_fake, d_loss_real, d_loss_fake, g_loss],\n",
    "                                                    {x_placeholder: real_image_batch})\n",
    "        d_fake_count += 1\n",
    "\n",
    "    if gLoss > 0.5:\n",
    "        # Train the generator\n",
    "        _, dLossReal, dLossFake, gLoss = sess.run([g_trainer, d_loss_real, d_loss_fake, g_loss],\n",
    "                                                    {x_placeholder: real_image_batch})\n",
    "        g_count += 1\n",
    "\n",
    "    if dLossReal > 0.45:\n",
    "        # If the discriminator classifies real images as fake,\n",
    "        # train discriminator on real values\n",
    "        _, dLossReal, dLossFake, gLoss = sess.run([d_trainer_real, d_loss_real, d_loss_fake, g_loss],\n",
    "                                                    {x_placeholder: real_image_batch})\n",
    "        d_real_count += 1\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        real_image_batch = mnist.validation.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "        summary = sess.run(merged, {x_placeholder: real_image_batch, d_real_count_ph: d_real_count,\n",
    "                                    d_fake_count_ph: d_fake_count, g_count_ph: g_count})\n",
    "        writer.add_summary(summary, i)\n",
    "        d_real_count, d_fake_count, g_count = 0, 0, 0\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        # Periodically display a sample image in the notebook\n",
    "        # (These are also being sent to TensorBoard every 10 iterations)\n",
    "        images = sess.run(generator(3, z_dimensions))\n",
    "        d_result = sess.run(discriminator(x_placeholder), {x_placeholder: images})\n",
    "        print(\"TRAINING STEP\", i, \"AT\", datetime.datetime.now())\n",
    "        for j in range(3):\n",
    "            print(\"Discriminator classification\", d_result[j])\n",
    "            im = images[j, :, :, 0]\n",
    "            plt.imshow(im.reshape([28, 28]), cmap='Greys')\n",
    "            plt.show()\n",
    "\n",
    "    if i % 5000 == 0:\n",
    "        save_path = saver.save(sess, \"models/pretrained_gan.ckpt\", global_step=i)\n",
    "        print(\"saved to %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see some of the images produced by the generator. (The generator has also been sending its images to TensorBoard regularly; click the \"images\" tab in TensorBoard to see them as this runs.)\n",
    "\n",
    "And, as a sanity check, let's look at some real MNIST images and make sure that the discriminator correctly classifies them as real MINST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_images = sess.run(generator(10, 100))\n",
    "test_eval = sess.run(discriminator(x_placeholder), {x_placeholder: test_images})\n",
    "\n",
    "real_images = mnist.validation.next_batch(10)[0].reshape([10, 28, 28, 1])\n",
    "real_eval = sess.run(discriminator(x_placeholder), {x_placeholder: real_images})\n",
    "\n",
    "# Show discriminator's probabilities for the generated images,\n",
    "# and display the images\n",
    "for i in range(10):\n",
    "    print(test_eval[i])\n",
    "    plt.imshow(test_images[i, :, :, 0], cmap='Greys')\n",
    "    plt.show()\n",
    "\n",
    "# Now do the same for real MNIST images\n",
    "for i in range(10):\n",
    "    print(real_eval[i])\n",
    "    plt.imshow(real_images[i, :, :, 0], cmap='Greys')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
